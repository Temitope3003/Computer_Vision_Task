{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y)= mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28), (60000,), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale dataset\n",
    "train_x = train_x.astype('float32')/255\n",
    "test_x = test_x.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #normalization\n",
    "# train_x = train_x.astype('float32') - 127.5/ 127.5\n",
    "# test_x = test_x.astype('float32') - 127.5/127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten the image pixels\n",
    "train_x = train_x.reshape(60000, 784)#784 is 28 multiply by 28\n",
    "test_x =  test_x.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we reshape each of our 28 x 28 pixels into a 1 Dimensional array of 784 \n",
    "pixels (28 * 28)\n",
    "This is an undesirable but necessary step. Undesirable because by flattening our \n",
    "image into a single dimension, the entire 2 D structure of the image is lost. It is \n",
    "necessary because the fully connected neural network we are about to develop \n",
    "cannot handle such high dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the labels to Vectors\n",
    "train_y = keras.utils.to_categorical(train_y,10)\n",
    "test_y = keras.utils.to_categorical(test_y,10)\n",
    "#this seems like using one hot encoding to eencode the 10 classes in the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #define the model network\n",
    "# model = Sequential()\n",
    "# model.add(Dense(units= 128, activation= 'relu', input_shape = (784,)))\n",
    "# model.add(Dense(units= 128, activation= 'relu'))\n",
    "# model.add(Dense(units= 128, activation= 'relu'))\n",
    "# model.add(Dense(units= 10, activation= 'softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input shape passed to the first layer is necessary for keras to determine the shape of the data. In this case, the shape of each 28 x 28 image has become 784 after we flatten it.\n",
    "\n",
    "The last layer uses the softmax function we explained under Loss Functions. Since \n",
    "our classes are ten, 0 – 9, this final output layer needs exactly ten neurons to \n",
    "output ten softmax computed probabilities for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #compile the function\n",
    "# model.compile(optimizer = SGD(0.01), loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is very vital to our training procedure, first we specify the optimizer, which in this case is SGD (Stochastic Gradient Descent) with a learning rate of 0.01. This is a very \n",
    "good learning rate value, if it is too small, training would become unnecessarily slow, while if it’s too high, SGD is likely to overshoot, failing to converge to neither a global \n",
    "minima nor a local minima.\n",
    "\n",
    "Next we specify our loss function, in this case categorical_crossentropy , just another name for softmax crossentropy.\n",
    "\n",
    "Finally, we state the metrics we want to obtain, in this case we are most interested in the accuracy, i.e the ratio of images classified correctly. In a classification setting, we are most interested in the accuracy metric, however, in regression setting, we are primarily concerned with the Mean Squared Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fit the function\n",
    "# model.fit(train_x, train_y, batch_size= 32, epochs= 10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we pass the training images and their corresponding labels into our model, we also specify the batch size to be 32. This entails we want the model to process only 32 images at a time, finally, we specify that training should run for 10 \n",
    "iterations. Note that at each iteration, the training would be done on all the batches. In this case, each of the 10 iterations is divided into 60000/32 iterations.\n",
    "Verbose = 1 simply tells keras to log to the console at every iteration.\n",
    "\n",
    "Calling the fit function would invoke the training process right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = model.evaluate(x= test_x, y = test_y, batch_size= 32)\n",
    "# print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model network\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(units= 256, activation= 'relu',input_shape = (784,)))\n",
    "model2.add(Dense(units= 256, activation= 'relu'))\n",
    "model2.add(Dense(units= 256, activation= 'relu'))\n",
    "model2.add(Dense(units= 10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 335114 (1.28 MB)\n",
      "Trainable params: 335114 (1.28 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model by specifying the input shape\n",
    "model2.build(input_shape=(None, 784))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the function\n",
    "model2.compile(optimizer ='Adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 15s 7ms/step - loss: 0.2019 - accuracy: 0.9385\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0905 - accuracy: 0.9722\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0644 - accuracy: 0.9798\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0511 - accuracy: 0.9840\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0388 - accuracy: 0.9876\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0356 - accuracy: 0.9890\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0303 - accuracy: 0.9906\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0253 - accuracy: 0.9920\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0241 - accuracy: 0.9923\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0228 - accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x157eba7f3d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the function\n",
    "model2.fit(train_x, train_y, batch_size= 32, epochs= 10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the neuron size increases the accuracy to 99% at 10 epochs\n",
    "\n",
    "while changing the optimizers also increased the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 0.1014 - accuracy: 0.9775\n",
      "Accuracy:  [0.10138635337352753, 0.9775000214576721]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the accuracy of the test dataset\n",
    "accuracy2 = model2.evaluate(x=test_x,y=test_y,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\comp_vision\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model2.save('mnistmodel22.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
