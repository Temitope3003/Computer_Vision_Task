{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Conv2D,  Flatten, AveragePooling2D,MaxPooling2D, Dropout, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images:  (50000, 32, 32, 3)\n",
      "Train Labels:  (50000, 1)\n",
      "Test Images:  (10000, 32, 32, 3)\n",
      "Test Labels:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#load the mnist dataset\n",
    "(train_x, train_y) , (test_x, test_y) = cifar10.load_data()\n",
    "#normalize the data\n",
    "train_x = train_x.astype('float32') / 255\n",
    "test_x = test_x.astype('float32') / 255\n",
    "#print the shapes of the data arrays\n",
    "print(\"Train Images: \",train_x.shape)\n",
    "print(\"Train Labels: \",train_y.shape)\n",
    "print(\"Test Images: \",test_x.shape)\n",
    "print(\"Test Labels: \",test_y.shape)\n",
    "#Encode the labels to vectors\n",
    "train_y = keras.utils.to_categorical(train_y,10)\n",
    "test_y = keras.utils.to_categorical(test_y,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model\n",
    "def MiniModel(input_shape):\n",
    "  images = Input(input_shape)\n",
    "\n",
    "  net = BatchNormalization()(images)\n",
    "  net = Activation('relu')(net)\n",
    "  net = Conv2D(filters= 64, kernel_size= [3,3], strides = [1,1], padding= 'same')(net)\n",
    "\n",
    "  net = BatchNormalization()(net)\n",
    "  net = Activation('relu')(net)\n",
    "  net = Conv2D(filters= 64, kernel_size= [3,3], strides = [1,1], padding= 'same')(net)\n",
    "\n",
    "  net = BatchNormalization()(net)\n",
    "  net = Activation('relu')(net)\n",
    "  net = Conv2D(filters= 64, kernel_size= [3,3], strides = [1,1], padding= 'same', activation= 'relu')(net)\n",
    "  net = MaxPooling2D(pool_size= (2,2))(net)\n",
    "\n",
    "  net = BatchNormalization()(net)\n",
    "  net = Activation('relu')(net)\n",
    "  net = Conv2D(filters= 64, kernel_size= [3,3], strides = [1,1], padding= 'same')(net)\n",
    "\n",
    "  net = BatchNormalization()(net)\n",
    "  net = Activation('relu')(net)\n",
    "  net = Conv2D(filters= 64, kernel_size= [3,3], strides = [1,1], padding= 'same', activation= 'relu')(net)\n",
    "  \n",
    "  \n",
    "\n",
    "  net = BatchNormalization()(net)\n",
    "  net = Activation('relu')(net)\n",
    "  net = Conv2D(filters= 64, kernel_size= [3,3], strides = [1,1], padding= 'same', activation= 'relu')(net)\n",
    "  net = MaxPooling2D(pool_size= (2,2))(net)\n",
    "\n",
    "  net = BatchNormalization()(net)\n",
    "  net = Activation('relu')(net)\n",
    "  net = Conv2D(filters= 64, kernel_size= [3,3], strides = [1,1], padding= 'same', activation= 'relu')(net)\n",
    "\n",
    "  net = BatchNormalization()(net)\n",
    "  net = Activation('relu')(net)\n",
    "  net = Conv2D(filters= 64, kernel_size= [3,3], strides = [1,1], padding= 'same', activation= 'relu')(net)\n",
    "\n",
    "  net = BatchNormalization()(net)\n",
    "  net = Activation('relu')(net)\n",
    "  net = Conv2D(filters= 64, kernel_size= [3,3], strides = [1,1], padding= 'same', activation= 'relu')(net)\n",
    "\n",
    "  net = BatchNormalization()(net)\n",
    "  net = Activation('relu')(net)\n",
    "  net = Conv2D(filters= 64, kernel_size= [3,3], strides = [1,1], padding= 'same', activation= 'relu')(net)\n",
    "\n",
    "  net = Dropout(0.25)(net)\n",
    "  net = AveragePooling2D(pool_size= (8,8))(net)\n",
    "  net = Flatten()(net)\n",
    "  net = Dense(units = 10, activation = 'softmax')(net)\n",
    "\n",
    "  model = Model(inputs = images, outputs = net)\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "input_shape = (32,32,3)\n",
    "model = MiniModel(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 32, 32, 3)         12        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 32, 32, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 32, 32, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 16, 16, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 16, 16, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 16, 16, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 16, 16, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 8, 8, 64)          256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 8, 8, 64)          256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 8, 8, 64)          256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 8, 8, 64)          256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 1, 1, 64)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 337110 (1.29 MB)\n",
      "Trainable params: 335952 (1.28 MB)\n",
      "Non-trainable params: 1158 (4.52 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Learning rate schedule function\n",
    "def lr_schedule(epoch):\n",
    "  lr = 0.001\n",
    "  if epoch > 15:\n",
    "    lr = lr / 100\n",
    "  elif epoch > 10:\n",
    "    lr = lr / 10\n",
    "  elif epoch > 5:\n",
    "    lr = lr / 5\n",
    "  print(\"Learning Rate: \",lr)\n",
    "  \n",
    "  return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass the scheduler function to the Learning Rate Scheduler class\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory in which to create models\n",
    "save_direc = os.path.join(os.getcwd(), 'cifar10savedmodels')\n",
    "\n",
    "#Name of model files\n",
    "model_name = 'cifar10model.{epoch:03d}.h5'\n",
    "\n",
    "\n",
    "#Create Directory if it doesn't exist\n",
    "if not os.path.isdir(save_direc):\n",
    " os.makedirs(save_direc)\n",
    "\n",
    "\n",
    "#Join the directory with the model file\n",
    "modelpath = os.path.join(save_direc, model_name)\n",
    "\n",
    "#Join the directory with the model file\n",
    "modelpath = os.path.join(save_direc, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(filepath= modelpath,\n",
    "                             monitor= 'val_acc',\n",
    "                             verbose= 1,\n",
    "                             save_best_only= True,\n",
    "                             period = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate:  0.001\n"
     ]
    }
   ],
   "source": [
    "#Specify the training components\n",
    "model.compile(optimizer=Adam(lr_schedule(0)),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate:  0.001\n",
      "Epoch 1/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 1.5272 - accuracy: 0.4401WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 1834s 5s/step - loss: 1.5272 - accuracy: 0.4401 - val_loss: 1.7019 - val_accuracy: 0.4202 - lr: 0.0010\n",
      "Learning Rate:  0.001\n",
      "Epoch 2/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 1.0466 - accuracy: 0.6280WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 1643s 5s/step - loss: 1.0466 - accuracy: 0.6280 - val_loss: 1.2841 - val_accuracy: 0.6004 - lr: 0.0010\n",
      "Learning Rate:  0.001\n",
      "Epoch 3/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.7898 - accuracy: 0.7251WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 1537s 4s/step - loss: 0.7898 - accuracy: 0.7251 - val_loss: 0.8208 - val_accuracy: 0.7202 - lr: 0.0010\n",
      "Learning Rate:  0.001\n",
      "Epoch 4/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.6225 - accuracy: 0.7839WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 1639s 5s/step - loss: 0.6225 - accuracy: 0.7839 - val_loss: 0.7856 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Learning Rate:  0.001\n",
      "Epoch 5/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.5182 - accuracy: 0.8208WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 3407s 10s/step - loss: 0.5182 - accuracy: 0.8208 - val_loss: 0.7481 - val_accuracy: 0.7552 - lr: 0.0010\n",
      "Learning Rate:  0.001\n",
      "Epoch 6/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4380 - accuracy: 0.8475WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 1887s 5s/step - loss: 0.4380 - accuracy: 0.8475 - val_loss: 0.7061 - val_accuracy: 0.7680 - lr: 0.0010\n",
      "Learning Rate:  0.0002\n",
      "Epoch 7/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2774 - accuracy: 0.9056 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 4605s 13s/step - loss: 0.2774 - accuracy: 0.9056 - val_loss: 0.5075 - val_accuracy: 0.8302 - lr: 2.0000e-04\n",
      "Learning Rate:  0.0002\n",
      "Epoch 8/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9279WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 1268s 4s/step - loss: 0.2151 - accuracy: 0.9279 - val_loss: 0.5217 - val_accuracy: 0.8366 - lr: 2.0000e-04\n",
      "Learning Rate:  0.0002\n",
      "Epoch 9/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1771 - accuracy: 0.9409WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 1247s 4s/step - loss: 0.1771 - accuracy: 0.9409 - val_loss: 0.5291 - val_accuracy: 0.8422 - lr: 2.0000e-04\n",
      "Learning Rate:  0.0002\n",
      "Epoch 10/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.9518WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 1195s 3s/step - loss: 0.1446 - accuracy: 0.9518 - val_loss: 0.5717 - val_accuracy: 0.8378 - lr: 2.0000e-04\n",
      "Learning Rate:  0.0002\n",
      "Epoch 11/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.9622WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 1237s 4s/step - loss: 0.1160 - accuracy: 0.9622 - val_loss: 0.6509 - val_accuracy: 0.8240 - lr: 2.0000e-04\n",
      "Learning Rate:  0.0001\n",
      "Epoch 12/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9770WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 1199s 3s/step - loss: 0.0771 - accuracy: 0.9770 - val_loss: 0.6186 - val_accuracy: 0.8386 - lr: 1.0000e-04\n",
      "Learning Rate:  0.0001\n",
      "Epoch 13/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9825WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 1209s 3s/step - loss: 0.0621 - accuracy: 0.9825 - val_loss: 0.6585 - val_accuracy: 0.8380 - lr: 1.0000e-04\n",
      "Learning Rate:  0.0001\n",
      "Epoch 14/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9868WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 1255s 4s/step - loss: 0.0493 - accuracy: 0.9868 - val_loss: 0.6892 - val_accuracy: 0.8378 - lr: 1.0000e-04\n",
      "Learning Rate:  0.0001\n",
      "Epoch 15/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9890WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 1188s 3s/step - loss: 0.0429 - accuracy: 0.9890 - val_loss: 0.7137 - val_accuracy: 0.8344 - lr: 1.0000e-04\n",
      "Learning Rate:  0.0001\n",
      "Epoch 16/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9911WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 1187s 3s/step - loss: 0.0368 - accuracy: 0.9911 - val_loss: 0.7491 - val_accuracy: 0.8348 - lr: 1.0000e-04\n",
      "Learning Rate:  1e-05\n",
      "Epoch 17/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9951WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 1188s 3s/step - loss: 0.0261 - accuracy: 0.9951 - val_loss: 0.7464 - val_accuracy: 0.8376 - lr: 1.0000e-05\n",
      "Learning Rate:  1e-05\n",
      "Epoch 18/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9961WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 1215s 3s/step - loss: 0.0232 - accuracy: 0.9961 - val_loss: 0.7467 - val_accuracy: 0.8368 - lr: 1.0000e-05\n",
      "Learning Rate:  1e-05\n",
      "Epoch 19/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9963WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 1191s 3s/step - loss: 0.0221 - accuracy: 0.9963 - val_loss: 0.7528 - val_accuracy: 0.8370 - lr: 1.0000e-05\n",
      "Learning Rate:  1e-05\n",
      "Epoch 20/20\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9967  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "352/352 [==============================] - 137049s 390s/step - loss: 0.0210 - accuracy: 0.9967 - val_loss: 0.7563 - val_accuracy: 0.8368 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x206cbeba7d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model\n",
    "model.fit(train_x,train_y,batch_size=128,epochs=20,shuffle=True,validation_split=0.1,verbose=1,callbacks=[checkpoint,lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 83s 1s/step - loss: 0.8048 - accuracy: 0.8293\n",
      "Accuracy:  0.8292999863624573\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the accuracy of the test dataset\n",
    "accuracy = model.evaluate(x=test_x,y=test_y,batch_size=128)\n",
    "print(\"Accuracy: \",accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
