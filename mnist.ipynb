{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks. They are the best and most effective for all tasks \n",
    "where the order or arrangement of the data is of absolute importance. Computer \n",
    "Vision and Pattern Recognition falls into this category. Convolutional Neural \n",
    "Networks, henceforth to be called CNNs, were pioneered by Yann LeCun et al in \n",
    "1998."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs are feed-forward networks, just like the vanilla neural networks, however, \n",
    "they are locally connected while the vanilla neural networks are fully connected.\n",
    "\n",
    "\n",
    "CNNs work by detecting specific patterns or features across the entire image.\n",
    "\n",
    "CNNs are incredibly effective at detecting patterns, hence, Deep Computer Vision \n",
    "rests heavily on their shoulders.\n",
    "\n",
    " The number of pixels by which the convolutions move is called \n",
    "the stride and can be more than one\n",
    "\n",
    "we use padding to ensure the dimensions remain unaltered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the mnist dataset\n",
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the data\n",
    "train_x = train_x.astype('float32')/255\n",
    "test_x = test_x.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape from (28,28) to (28,28,1) for the x = features\n",
    "train_x = train_x.reshape(train_x.shape[0], 28,28,1)\n",
    "test_x = test_x.reshape(test_x.shape[0], 28,28,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the labels which is the y = labels\n",
    "train_y = keras.utils.to_categorical(train_y, 10)\n",
    "test_y = keras.utils.to_categorical(test_y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MiniModel(input_shape):\n",
    "  images = Input(input_shape)\n",
    "  net = Conv2D(filters= 64, kernel_size=[3,3], strides= [1,1], padding= 'same', activation= 'relu')(images)\n",
    "  net = Conv2D(filters= 64, kernel_size=[3,3], strides= [1,1], padding= 'same', activation= 'relu')(net)\n",
    "  net = MaxPooling2D(pool_size= (2,2))(net) \n",
    "  net = Conv2D(filters= 128, kernel_size=[3,3], strides= [1,1], padding= 'same', activation= 'relu')(net)\n",
    "  net = Conv2D(filters= 128, kernel_size=[3,3], strides= [1,1], padding= 'same', activation= 'relu')(net)\n",
    "  net = Flatten()(net)\n",
    "  net = Dense(units = 10, activation= 'softmax')(net)\n",
    "\n",
    "  model = Model(inputs = images, outputs = net)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28,28,1)\n",
    "model = MiniModel(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 64)        640       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                250890    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 509898 (1.95 MB)\n",
      "Trainable params: 509898 (1.95 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function for the learning rate\n",
    "def lr_schedule(epoch):\n",
    "  lr = 0.1\n",
    "\n",
    "  if epoch > 15:\n",
    "    lr = lr/ 100\n",
    "\n",
    "  elif epoch > 10:\n",
    "    lr = lr/10\n",
    "\n",
    "  elif epoch > 5:\n",
    "    lr = lr/5\n",
    "\n",
    "  print('Learning Rate: ', lr)\n",
    "\n",
    "  return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass the learning rate scheduler to the learning rate class\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory in which to create models\n",
    "save_direc = os.path.join(os.getcwd(), 'mnistsavedmodels_cnn')\n",
    "\n",
    "#name of models file\n",
    "model_name= 'mnistmodel_cnn.{epoch:03d}.h5'\n",
    "\n",
    "#create directory if it doesnt exist\n",
    "if not os.path.isdir(save_direc):\n",
    "  os.makedirs(save_direc)\n",
    "\n",
    "#join the directory with model path\n",
    "modelpath = os.path.join(save_direc, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(filepath= modelpath,\n",
    "                             monitor= 'val_acc',\n",
    "                             verbose= 1,\n",
    "                             save_best_only= True,\n",
    "                             period = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate:  0.1\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer= SGD(lr_schedule(0)), loss= 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate:  0.1\n",
      "Epoch 1/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.9327WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 699s 826ms/step - loss: 0.2175 - accuracy: 0.9327 - val_loss: 0.0674 - val_accuracy: 0.9802 - lr: 0.1000\n",
      "Learning Rate:  0.1\n",
      "Epoch 2/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9827WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 639s 757ms/step - loss: 0.0565 - accuracy: 0.9827 - val_loss: 0.0752 - val_accuracy: 0.9792 - lr: 0.1000\n",
      "Learning Rate:  0.1\n",
      "Epoch 3/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9881WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 601s 712ms/step - loss: 0.0391 - accuracy: 0.9881 - val_loss: 0.0485 - val_accuracy: 0.9860 - lr: 0.1000\n",
      "Learning Rate:  0.1\n",
      "Epoch 4/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9901WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 595s 704ms/step - loss: 0.0305 - accuracy: 0.9901 - val_loss: 0.0373 - val_accuracy: 0.9900 - lr: 0.1000\n",
      "Learning Rate:  0.1\n",
      "Epoch 5/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9926WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 462s 548ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.0438 - val_accuracy: 0.9890 - lr: 0.1000\n",
      "Learning Rate:  0.1\n",
      "Epoch 6/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9941WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 448s 531ms/step - loss: 0.0172 - accuracy: 0.9941 - val_loss: 0.0510 - val_accuracy: 0.9882 - lr: 0.1000\n",
      "Learning Rate:  0.02\n",
      "Epoch 7/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9977WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 463s 549ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.0380 - val_accuracy: 0.9912 - lr: 0.0200\n",
      "Learning Rate:  0.02\n",
      "Epoch 8/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9989WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 404s 478ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0424 - val_accuracy: 0.9915 - lr: 0.0200\n",
      "Learning Rate:  0.02\n",
      "Epoch 9/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9990WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 376s 446ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0420 - val_accuracy: 0.9918 - lr: 0.0200\n",
      "Learning Rate:  0.02\n",
      "Epoch 10/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 556s 659ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0437 - val_accuracy: 0.9913 - lr: 0.0200\n",
      "Learning Rate:  0.02\n",
      "Epoch 11/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 804s 952ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0455 - val_accuracy: 0.9917 - lr: 0.0200\n",
      "Learning Rate:  0.01\n",
      "Epoch 12/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9996WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 534s 633ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0455 - val_accuracy: 0.9913 - lr: 0.0100\n",
      "Learning Rate:  0.01\n",
      "Epoch 13/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9996WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 587s 696ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0472 - val_accuracy: 0.9913 - lr: 0.0100\n",
      "Learning Rate:  0.01\n",
      "Epoch 14/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 538s 637ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0475 - val_accuracy: 0.9915 - lr: 0.0100\n",
      "Learning Rate:  0.01\n",
      "Epoch 15/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 541s 641ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0481 - val_accuracy: 0.9912 - lr: 0.0100\n",
      "Learning Rate:  0.01\n",
      "Epoch 16/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9998WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 694s 822ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0494 - val_accuracy: 0.9917 - lr: 0.0100\n",
      "Learning Rate:  0.001\n",
      "Epoch 17/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 621s 736ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0495 - val_accuracy: 0.9913 - lr: 0.0010\n",
      "Learning Rate:  0.001\n",
      "Epoch 18/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 632s 749ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0496 - val_accuracy: 0.9915 - lr: 0.0010\n",
      "Learning Rate:  0.001\n",
      "Epoch 19/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 705s 835ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0497 - val_accuracy: 0.9915 - lr: 0.0010\n",
      "Learning Rate:  0.001\n",
      "Epoch 20/20\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "844/844 [==============================] - 655s 776ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0498 - val_accuracy: 0.9915 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e9a85b7f90>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size = 64, epochs = 20, validation_split= 0.1, verbose= 1, callbacks=[checkpoint, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 34s 213ms/step - loss: 0.0381 - accuracy: 0.9909\n",
      "Accuracy:  0.9908999800682068\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the accuracy of the test dataset\n",
    "accuracy = model.evaluate(x=test_x,y=test_y,batch_size=64)\n",
    "\n",
    "print(\"Accuracy: \",accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\comp_vision\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('mnist_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
